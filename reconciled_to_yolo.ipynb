{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d580580",
   "metadata": {},
   "source": [
    "# Convert reconciled bounding boxes into YOLO training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debeafc9",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f05ee2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from os import makedirs\n",
    "from pathlib import Path\n",
    "from shutil import rmtree\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from digi_leap.subject import Subject, RECONCILE_TYPES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce459f6",
   "metadata": {},
   "source": [
    "## Data that may change for each user or run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf38b6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path.cwd() / 'data'\n",
    "\n",
    "LABEL_BABEL_2_DIR = DATA_DIR / 'label-babel-2'\n",
    "SHEETS_2_DIR = LABEL_BABEL_2_DIR / 'herbarium-sheets-small'\n",
    "\n",
    "RECONCILED = LABEL_BABEL_2_DIR / '17633_label_babel_2.reconciled.csv'\n",
    "TRAIN_CSV = LABEL_BABEL_2_DIR / '17633_label_babel_2.train.csv'\n",
    "\n",
    "YOLO_TRAIN_CSV = LABEL_BABEL_2_DIR / '17633_label_babel_2.yolo.train.csv'\n",
    "YOLO_VAL_CSV = LABEL_BABEL_2_DIR / '17633_label_babel_2.yolo.val.csv'\n",
    "\n",
    "YOLO_DIR = LABEL_BABEL_2_DIR / 'yolo'\n",
    "\n",
    "IMAGE_TRAIN_DIR = YOLO_DIR / 'images' / 'train'\n",
    "IMAGE_VAL_DIR = YOLO_DIR / 'images' / 'val'\n",
    "LABEL_TRAIN_DIR = YOLO_DIR / 'labels' / 'train'\n",
    "LABEL_VAL_DIR = YOLO_DIR / 'labels' / 'val'\n",
    "\n",
    "SEED = 4484"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc153217",
   "metadata": {},
   "source": [
    "Should data be removed from the YOLO training and validation directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c792dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN_YOLO = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2c1214",
   "metadata": {},
   "source": [
    "Resize images to this width and height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bf9005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 640"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe384a75",
   "metadata": {},
   "source": [
    "How much of the data goes towards validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c7d5937",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_SPLIT = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243fac2c",
   "metadata": {},
   "source": [
    "Keep prints of numpy arrays reasonably pretty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e79c9fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac828a1",
   "metadata": {},
   "source": [
    "## Create directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "568fb007",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLEAN_YOLO:\n",
    "    rmtree(IMAGE_TRAIN_DIR, ignore_errors=True)\n",
    "    rmtree(IMAGE_VAL_DIR, ignore_errors=True)\n",
    "    rmtree(LABEL_TRAIN_DIR, ignore_errors=True)\n",
    "    rmtree(LABEL_VAL_DIR, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e916fbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "makedirs(IMAGE_TRAIN_DIR, exist_ok=True)\n",
    "makedirs(IMAGE_VAL_DIR, exist_ok=True)\n",
    "makedirs(LABEL_TRAIN_DIR, exist_ok=True)\n",
    "makedirs(LABEL_VAL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634b3382",
   "metadata": {},
   "source": [
    "## Read the reconciled training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d77f390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_CSV) as csv_file:\n",
    "    reader = csv.DictReader(csv_file)\n",
    "    subjects = [r for r in reader]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8af3aed",
   "metadata": {},
   "source": [
    "## Split into training and validation data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de2b56ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rows, val_rows = train_test_split(\n",
    "    subjects, test_size=VAL_SPLIT, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ef3c72",
   "metadata": {},
   "source": [
    "## Write resized images to training and validation directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0e1b0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_resized(row, image_dir):\n",
    "    src = SHEETS_2_DIR / row['image_file']\n",
    "    dst = image_dir / row['image_file']\n",
    "    image = Image.open(src)\n",
    "    row['image_size'] = image.size\n",
    "    image = image.resize((IMAGE_SIZE, IMAGE_SIZE))\n",
    "    image.save(dst)\n",
    "    row['resized'] = [IMAGE_SIZE, IMAGE_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "734e6c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2996/2996 [02:44<00:00, 18.17it/s]\n",
      "100%|██████████| 999/999 [00:55<00:00, 17.95it/s]\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm(train_rows):\n",
    "    size = json.loads(row['image_size'])\n",
    "    row['image_size'] = [size['width'], size['height']]\n",
    "    row['resized'] = [IMAGE_SIZE, IMAGE_SIZE]    \n",
    "    if CLEAN_YOLO:\n",
    "        write_resized(row, IMAGE_TRAIN_DIR)\n",
    "\n",
    "for row in tqdm(val_rows):\n",
    "    size = json.loads(row['image_size'])\n",
    "    row['image_size'] = [size['width'], size['height']]\n",
    "    row['resized'] = [IMAGE_SIZE, IMAGE_SIZE]    \n",
    "    if CLEAN_YOLO:\n",
    "        write_resized(row, IMAGE_VAL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9a5cd4",
   "metadata": {},
   "source": [
    "## Create machine learning labels from herbarium label types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53d6701b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2996/2996 [00:00<00:00, 39449.78it/s]\n",
      "100%|██████████| 999/999 [00:00<00:00, 41547.94it/s]\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm(train_rows):\n",
    "    types = [v for k, v in row.items() if k.startswith('merged_type_')]\n",
    "    for i, label in enumerate(types, 1):\n",
    "        row[f'label_{i}'] = RECONCILE_TYPES[label.strip('_')]\n",
    "\n",
    "for row in tqdm(val_rows):\n",
    "    types = [v for k, v in row.items() if k.startswith('merged_type_')]\n",
    "    for i, label in enumerate(types, 1):\n",
    "        row[f'label_{i}'] = RECONCILE_TYPES[label.strip('_')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c141de29",
   "metadata": {},
   "source": [
    "## Resize bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a5a61da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_boxes(row):\n",
    "    width, height = row['image_size']\n",
    "\n",
    "    boxes = [v for k, v in row.items() if k.startswith('merged_box_') and v]\n",
    "    boxes = np.array([Subject.bbox_from_json(b, (width, height)) for b in boxes],\n",
    "                     dtype=np.float32)\n",
    "\n",
    "    if len(boxes) == 0:\n",
    "        return\n",
    "\n",
    "    boxes[:, [0, 2]] *= row['resized'][0] / width\n",
    "    boxes[:, [1, 3]] *= row['resized'][1] / height\n",
    "    boxes = np.floor(boxes)\n",
    "\n",
    "    for i, box in enumerate(boxes, 1):\n",
    "        row[f'resized_{i}'] = box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74780c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2996/2996 [00:00<00:00, 4394.24it/s]\n",
      "100%|██████████| 999/999 [00:00<00:00, 4805.30it/s]\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm(train_rows):\n",
    "    resize_boxes(row)\n",
    "\n",
    "for row in tqdm(val_rows):\n",
    "    resize_boxes(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50965dd",
   "metadata": {},
   "source": [
    "## Convert resized bounding boxes for a subject into YOLO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97a29fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_yolo(row):\n",
    "    width, height = row['resized']\n",
    "\n",
    "    boxes = [v for k, v in row.items() if k.startswith('resized_') and len(v)]\n",
    "    boxes = np.array(boxes, dtype=np.float32)\n",
    "\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    center_x = (boxes[:, 0] + boxes[:, 2]) / 2.0\n",
    "    center_y = (boxes[:, 1] + boxes[:, 3]) / 2.0\n",
    "    wide = boxes[:, 2] - boxes[:, 0] + 1\n",
    "    high = boxes[:, 3] - boxes[:, 1] + 1\n",
    "    boxes = np.vstack((center_x, center_y, wide, high)).transpose()\n",
    "    boxes[:, [0, 2]] /= width\n",
    "    boxes[:, [1, 3]] /= height\n",
    "\n",
    "    for i, box in enumerate(boxes, 1):\n",
    "        row[f'yolo_{i}'] = box\n",
    "\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f991d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2996/2996 [00:00<00:00, 14636.22it/s]\n",
      "100%|██████████| 999/999 [00:00<00:00, 16188.03it/s]\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm(train_rows):\n",
    "    to_yolo(row)\n",
    "\n",
    "for row in tqdm(val_rows):\n",
    "    to_yolo(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f984f7",
   "metadata": {},
   "source": [
    "## Save the reworked training and validation CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a35a0097",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(train_rows)\n",
    "df.to_csv(YOLO_TRAIN_CSV, index=False)\n",
    "\n",
    "df = pd.DataFrame(val_rows)\n",
    "df.to_csv(YOLO_VAL_CSV, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b11fef",
   "metadata": {},
   "source": [
    "## Write YOLO bounding boxes to training and validation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9b8b83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_yolo(row, label_dir):\n",
    "    path = Path(row['image_file']).stem\n",
    "    path = label_dir / f'{path}.txt'\n",
    "\n",
    "    boxes = to_yolo(row)\n",
    "    labels = [v for k, v in row.items() if k.startswith('label_')]\n",
    "\n",
    "    if len(boxes) == 0:\n",
    "        return\n",
    "\n",
    "    with open(path, 'w') as out_file:\n",
    "        for label, box in zip(labels, boxes):\n",
    "            bbox = np.array2string(box, formatter={'float_kind': lambda x: \"%.6f\" % x})\n",
    "            out_file.write(f'{label} {bbox[1:-1]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14e817bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2996/2996 [00:00<00:00, 3464.42it/s]\n",
      "100%|██████████| 999/999 [00:00<00:00, 3557.30it/s]\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm(train_rows):\n",
    "    write_yolo(row, LABEL_TRAIN_DIR)\n",
    "\n",
    "for row in tqdm(val_rows):\n",
    "    write_yolo(row, LABEL_VAL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fa810c",
   "metadata": {},
   "source": [
    "# Simple tests on the conversion to YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e5e5b9",
   "metadata": {},
   "source": [
    "## Show resized bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d22da7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_resized(idx):\n",
    "    row = train_rows[idx]\n",
    "\n",
    "    image = Image.open(IMAGE_TRAIN / row['image_file'])\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    boxes = [v for k, v in row.items() if k.startswith('resized_')]\n",
    "    for box in boxes:\n",
    "        draw.rectangle(box, outline='red', width=2)\n",
    "\n",
    "    display(image)\n",
    "\n",
    "\n",
    "# show_resized(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da21b00a",
   "metadata": {},
   "source": [
    "## Show YOLO bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b2ae7fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def show_yolo(idx):\n",
    "    row = train_rows[idx]\n",
    "\n",
    "    width, height = row['image_size']\n",
    "\n",
    "    image = Image.open(SHEETS_2 / row['image_file'])\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    boxes = [v for k, v in row.items() if k.startswith('merged_box_') and len(v)]\n",
    "    boxes = np.array([Subject.bbox_from_json(b, (width, height)) for b in boxes],\n",
    "                     dtype=np.float32)\n",
    "    for box in boxes:\n",
    "        draw.rectangle(box, outline='blue', width=4)\n",
    "\n",
    "    labels, boxes = to_yolo(row)\n",
    "\n",
    "    for box in boxes:\n",
    "        radius_x = (box[2] * width - 1) / 2\n",
    "        radius_y = (box[3] * height - 1) / 2\n",
    "        x0 = int(box[0] * width - radius_x)\n",
    "        y0 = int(box[1] * height - radius_y)\n",
    "        x1 = int(box[0] * width + radius_x)\n",
    "        y1 = int(box[1] * height + radius_y)\n",
    "        draw.rectangle((x0, y0, x1, y1), outline='red', width=2)\n",
    "\n",
    "    display(image)\n",
    "\n",
    "\n",
    "# show_yolo(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43dabfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
