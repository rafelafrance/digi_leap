{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load iDigBio Data for Label Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T17:06:15.221693Z",
     "start_time": "2021-03-03T17:06:15.103734Z"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import sqlite3\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T17:06:16.431837Z",
     "start_time": "2021-03-03T17:06:16.428886Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = Path('..') / 'data'\n",
    "\n",
    "NAME = 'occurrence_raw_idigbio_2021-02'\n",
    "\n",
    "ZIP = str(DATA_DIR / 'raw' / 'iDigBio_snapshot_2021-02.zip')\n",
    "CSV = str(DATA_DIR / 'raw' / f'{NAME}.csv')\n",
    "\n",
    "PREFIX = str(DATA_DIR / f'{NAME}_')\n",
    "FIRST = f'{PREFIX}01.csv'\n",
    "BACKUP = f'{PREFIX}01_header.csv'\n",
    "GLOB = PREFIX + '*.csv'\n",
    "\n",
    "CHUNK = 1_000_000\n",
    "LINES = 5_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T17:06:17.127487Z",
     "start_time": "2021-03-03T17:06:17.121196Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_headers(zip_file):\n",
    "    with zipfile.ZipFile(ZIP) as zippy:\n",
    "        with zippy.open(zip_file) as in_file:\n",
    "            headers = in_file.readline()\n",
    "    return [h.decode().strip() for h in sorted(headers.split(b','))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T17:06:19.892363Z",
     "start_time": "2021-03-03T17:06:19.889032Z"
    }
   },
   "outputs": [],
   "source": [
    "bad_names = \"\"\" group order references \"\"\".split()\n",
    "\n",
    "def get_columns(headers):\n",
    "    columns = {}\n",
    "    used = set()\n",
    "\n",
    "    for head in headers:\n",
    "        col = head.split(':')[-1]\n",
    "        col = re.sub(r'(?<![A-Z])([A-Z])', r'_\\1', col).lower()\n",
    "        col = re.sub(r'^_', '', col)\n",
    "        if col in used:\n",
    "            col = head.replace(':', '_')\n",
    "            col = re.sub(r'(?<![A-Z])([A-Z])', r'_\\1', col).lower()\n",
    "            col = re.sub(r'^_', '', col)\n",
    "        if col in bad_names:\n",
    "            col += '_'\n",
    "        columns[head] = col\n",
    "        used.add(col)\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T17:06:21.033917Z",
     "start_time": "2021-03-03T17:06:21.030751Z"
    }
   },
   "outputs": [],
   "source": [
    "def insert(zip_file, columns):\n",
    "    table = zip_file.split('.')[0]\n",
    "\n",
    "    with sqlite3.connect(DB) as cxn:\n",
    "        with zipfile.ZipFile(ZIP) as zippy:\n",
    "            with zippy.open(zip_file) as in_file:\n",
    "\n",
    "                reader = pd.read_csv(\n",
    "                    in_file, dtype=str, keep_default_na=False, chunksize=CHUNK)\n",
    "\n",
    "                if_exists = 'replace'\n",
    "\n",
    "                for df in tqdm(reader):\n",
    "                    df = df.rename(columns=columns)\n",
    "\n",
    "                    df.to_sql(table, cxn, if_exists=if_exists, index=False)\n",
    "\n",
    "                    if_exists = 'append'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T17:06:23.093819Z",
     "start_time": "2021-03-03T17:06:23.091058Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(zip_file):\n",
    "    headers = get_headers(zip_file)\n",
    "    columns = get_columns(headers)\n",
    "    insert(zip_file, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T17:06:25.102742Z",
     "start_time": "2021-03-03T17:06:25.100987Z"
    }
   },
   "outputs": [],
   "source": [
    "# load_data('occurrence_raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duck DB doubles the size of the data so we are not using it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic plan is:\n",
    "\n",
    "1. Extract occurrence_raw.csv from an iDigBio snapshot\n",
    "1. Get the headers and rename the columns so they'll work in a DB\n",
    "1. Split the CSV file into sizes that will fit in memory\n",
    "1. Load the CSV splits into the database\n",
    "1. Clean up the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make working with the database a bit easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the needed CSV file from the zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip -p $ZIP occurrence_raw.csv > $CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the CSV file into manageable chunks that fit in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !split --additional-suffix=.csv --numeric-suffixes=1 --lines=$LINES $CSV $PREFIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the first file with the header so it can be removed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mv $FIRST $BACKUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the headers from the first file. We need to rename the column headers in the DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(BACKUP) as in_file:\n",
    "#     headers = in_file.readline()\n",
    "# headers = [h.strip() for h in headers.split(',')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the old header from that first file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tail -n +2 $BACKUP > $FIRST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the backup file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm $BACKUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad_names = \"\"\" group order references \"\"\".split()\n",
    "\n",
    "# def get_columns(headers):\n",
    "#     columns = {}\n",
    "#     used = set()\n",
    "\n",
    "#     for head in headers:\n",
    "#         col = head.split(':')[-1]\n",
    "#         col = re.sub(r'(?<![A-Z])([A-Z])', r'_\\1', col).lower()\n",
    "#         col = re.sub(r'^_', '', col)\n",
    "#         if col in used:\n",
    "#             col = head.replace(':', '_')\n",
    "#             col = re.sub(r'(?<![A-Z])([A-Z])', r'_\\1', col).lower()\n",
    "#             col = re.sub(r'^_', '', col)\n",
    "#         if col in bad_names:\n",
    "#             col += '_'\n",
    "#         columns[head] = col\n",
    "#         used.add(col)\n",
    "#     return columns\n",
    "\n",
    "\n",
    "# columns = get_columns(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a table with the new column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = [f'{h} VARCHAR' for h in columns.values()]\n",
    "# columns = ', '.join(columns)\n",
    "\n",
    "# with duckdb_connect(DB) as cxn:\n",
    "#     cxn.execute(f'CREATE TABLE raw_data ({columns});')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy CSV data into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths = sorted(DATA_DIR.glob(GLOB))\n",
    "\n",
    "# for path in tqdm(paths):\n",
    "#     with duckdb_connect(DB) as cxn:\n",
    "#         cxn.execute(f\"COPY raw_data FROM '{str(path)}';\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unneeded files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path in paths:\n",
    "#     path.unlink()\n",
    "\n",
    "# Path(CSV).unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T12:52:32.402771Z",
     "start_time": "2020-05-09T12:41:37.652865Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0+"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
