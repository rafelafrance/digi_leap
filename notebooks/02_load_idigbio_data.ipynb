{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load iDigBio Data for Label Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T17:06:15.221693Z",
     "start_time": "2021-03-03T17:06:15.103734Z"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import sqlite3\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T17:06:16.431837Z",
     "start_time": "2021-03-03T17:06:16.428886Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = Path('..') / 'data'\n",
    "\n",
    "NAME = 'occurrence_raw_idigbio_2021-02'\n",
    "\n",
    "ZIP = str(DATA_DIR / 'raw' / 'iDigBio_snapshot_2021-02.zip')\n",
    "CSV = str(DATA_DIR / 'raw' / f'{NAME}.csv')\n",
    "\n",
    "PREFIX = str(DATA_DIR / f'{NAME}_')\n",
    "FIRST = f'{PREFIX}01.csv'\n",
    "BACKUP = f'{PREFIX}01_header.csv'\n",
    "GLOB = PREFIX + '*.csv'\n",
    "\n",
    "CHUNK = 1_000_000\n",
    "LINES = 5_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T17:06:17.127487Z",
     "start_time": "2021-03-03T17:06:17.121196Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_headers(zip_file):\n",
    "    with zipfile.ZipFile(ZIP) as zippy:\n",
    "        with zippy.open(zip_file) as in_file:\n",
    "            headers = in_file.readline()\n",
    "    return [h.decode().strip() for h in sorted(headers.split(b','))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T17:06:19.892363Z",
     "start_time": "2021-03-03T17:06:19.889032Z"
    }
   },
   "outputs": [],
   "source": [
    "bad_names = \"\"\" group order references \"\"\".split()\n",
    "\n",
    "def get_columns(headers):\n",
    "    columns = {}\n",
    "    used = set()\n",
    "\n",
    "    for head in headers:\n",
    "        col = head.split(':')[-1]\n",
    "        col = re.sub(r'(?<![A-Z])([A-Z])', r'_\\1', col).lower()\n",
    "        col = re.sub(r'^_', '', col)\n",
    "        if col in used:\n",
    "            col = head.replace(':', '_')\n",
    "            col = re.sub(r'(?<![A-Z])([A-Z])', r'_\\1', col).lower()\n",
    "            col = re.sub(r'^_', '', col)\n",
    "        if col in bad_names:\n",
    "            col += '_'\n",
    "        columns[head] = col\n",
    "        used.add(col)\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T17:06:21.033917Z",
     "start_time": "2021-03-03T17:06:21.030751Z"
    }
   },
   "outputs": [],
   "source": [
    "def insert(zip_file, columns):\n",
    "    table = zip_file.split('.')[0]\n",
    "\n",
    "    with sqlite3.connect(DB) as cxn:\n",
    "        with zipfile.ZipFile(ZIP) as zippy:\n",
    "            with zippy.open(zip_file) as in_file:\n",
    "\n",
    "                reader = pd.read_csv(\n",
    "                    in_file, dtype=str, keep_default_na=False, chunksize=CHUNK)\n",
    "\n",
    "                if_exists = 'replace'\n",
    "\n",
    "                for df in tqdm(reader):\n",
    "                    df = df.rename(columns=columns)\n",
    "\n",
    "                    df.to_sql(table, cxn, if_exists=if_exists, index=False)\n",
    "\n",
    "                    if_exists = 'append'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T17:06:23.093819Z",
     "start_time": "2021-03-03T17:06:23.091058Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(zip_file):\n",
    "    headers = get_headers(zip_file)\n",
    "    columns = get_columns(headers)\n",
    "    insert(zip_file, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coreid',\n",
       " 'dwc:basisOfRecord',\n",
       " 'dwc:bed',\n",
       " 'dwc:catalogNumber',\n",
       " 'dwc:class',\n",
       " 'dwc:collectionCode',\n",
       " 'dwc:collectionID',\n",
       " 'dwc:continent',\n",
       " 'dwc:coordinateUncertaintyInMeters',\n",
       " 'dwc:country',\n",
       " 'dwc:county',\n",
       " 'dwc:earliestAgeOrLowestStage',\n",
       " 'dwc:earliestEonOrLowestEonothem',\n",
       " 'dwc:earliestEpochOrLowestSeries',\n",
       " 'dwc:earliestEraOrLowestErathem',\n",
       " 'dwc:earliestPeriodOrLowestSystem',\n",
       " 'dwc:eventDate',\n",
       " 'dwc:family',\n",
       " 'dwc:fieldNumber',\n",
       " 'dwc:formation',\n",
       " 'dwc:genus',\n",
       " 'dwc:geologicalContextID',\n",
       " 'dwc:group',\n",
       " 'dwc:higherClassification',\n",
       " 'dwc:highestBiostratigraphicZone',\n",
       " 'dwc:individualCount',\n",
       " 'dwc:infraspecificEpithet',\n",
       " 'dwc:institutionCode',\n",
       " 'dwc:institutionID',\n",
       " 'dwc:kingdom',\n",
       " 'dwc:latestAgeOrHighestStage',\n",
       " 'dwc:latestEonOrHighestEonothem',\n",
       " 'dwc:latestEpochOrHighestSeries',\n",
       " 'dwc:latestEraOrHighestErathem',\n",
       " 'dwc:latestPeriodOrHighestSystem',\n",
       " 'dwc:lithostratigraphicTerms',\n",
       " 'dwc:locality',\n",
       " 'dwc:lowestBiostratigraphicZone',\n",
       " 'dwc:maximumDepthInMeters',\n",
       " 'dwc:maximumElevationInMeters',\n",
       " 'dwc:member',\n",
       " 'dwc:minimumDepthInMeters',\n",
       " 'dwc:minimumElevationInMeters',\n",
       " 'dwc:municipality',\n",
       " 'dwc:occurrenceID',\n",
       " 'dwc:order',\n",
       " 'dwc:phylum',\n",
       " 'dwc:recordNumber',\n",
       " 'dwc:recordedBy',\n",
       " 'dwc:scientificName',\n",
       " 'dwc:specificEpithet',\n",
       " 'dwc:startDayOfYear',\n",
       " 'dwc:stateProvince',\n",
       " 'dwc:taxonID',\n",
       " 'dwc:taxonRank',\n",
       " 'dwc:taxonomicStatus',\n",
       " 'dwc:typeStatus',\n",
       " 'dwc:verbatimEventDate',\n",
       " 'dwc:verbatimLocality',\n",
       " 'dwc:vernacularName',\n",
       " 'dwc:waterBody',\n",
       " 'gbif:canonicalName',\n",
       " 'idigbio:associatedsequences',\n",
       " 'idigbio:barcodeValue',\n",
       " 'idigbio:collectionName',\n",
       " 'idigbio:commonnames',\n",
       " 'idigbio:dataQualityScore',\n",
       " 'idigbio:dateModified',\n",
       " 'idigbio:etag',\n",
       " 'idigbio:eventDate',\n",
       " 'idigbio:flags',\n",
       " 'idigbio:geoPoint',\n",
       " 'idigbio:hasImage',\n",
       " 'idigbio:hasMedia',\n",
       " 'idigbio:institutionName',\n",
       " 'idigbio:isoCountryCode',\n",
       " 'idigbio:mediarecords',\n",
       " 'idigbio:recordIds',\n",
       " 'idigbio:recordset',\n",
       " 'idigbio:uuid',\n",
       " 'idigbio:version']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_headers('occurrence.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aec:associatedTaxa',\n",
       " 'coreid',\n",
       " 'dc:rights',\n",
       " 'dcterms:accessRights',\n",
       " 'dcterms:bibliographicCitation',\n",
       " 'dcterms:language',\n",
       " 'dcterms:license',\n",
       " 'dcterms:modified',\n",
       " 'dcterms:references',\n",
       " 'dcterms:rights',\n",
       " 'dcterms:rightsHolder',\n",
       " 'dcterms:source',\n",
       " 'dcterms:type',\n",
       " 'dwc:Identification',\n",
       " 'dwc:MeasurementOrFact',\n",
       " 'dwc:ResourceRelationship',\n",
       " 'dwc:VerbatimEventDate',\n",
       " 'dwc:acceptedNameUsage',\n",
       " 'dwc:accessRights',\n",
       " 'dwc:associatedMedia',\n",
       " 'dwc:associatedOccurrences',\n",
       " 'dwc:associatedOrganisms',\n",
       " 'dwc:associatedReferences',\n",
       " 'dwc:associatedSequences',\n",
       " 'dwc:associatedTaxa',\n",
       " 'dwc:basisOfRecord',\n",
       " 'dwc:bed',\n",
       " 'dwc:behavior',\n",
       " 'dwc:catalogNumber',\n",
       " 'dwc:class',\n",
       " 'dwc:classs',\n",
       " 'dwc:collectionCode',\n",
       " 'dwc:collectionID',\n",
       " 'dwc:continent',\n",
       " 'dwc:coordinatePrecision',\n",
       " 'dwc:coordinateUncertaintyInMeters',\n",
       " 'dwc:country',\n",
       " 'dwc:countryCode',\n",
       " 'dwc:county',\n",
       " 'dwc:dataGeneralizations',\n",
       " 'dwc:datasetID',\n",
       " 'dwc:datasetName',\n",
       " 'dwc:dateIdentified',\n",
       " 'dwc:day',\n",
       " 'dwc:decimalLatitude',\n",
       " 'dwc:decimalLongitude',\n",
       " 'dwc:disposition',\n",
       " 'dwc:dynamicProperties',\n",
       " 'dwc:earliestAgeOrLowestStage',\n",
       " 'dwc:earliestEonOrLowestEonothem',\n",
       " 'dwc:earliestEpochOrLowestSeries',\n",
       " 'dwc:earliestEraOrLowestErathem',\n",
       " 'dwc:earliestPeriodOrLowestSystem',\n",
       " 'dwc:endDayOfYear',\n",
       " 'dwc:establishmentMeans',\n",
       " 'dwc:eventDate',\n",
       " 'dwc:eventID',\n",
       " 'dwc:eventRemarks',\n",
       " 'dwc:eventTime',\n",
       " 'dwc:family',\n",
       " 'dwc:fieldNotes',\n",
       " 'dwc:fieldNumber',\n",
       " 'dwc:footprintSRS',\n",
       " 'dwc:footprintSpatialFit',\n",
       " 'dwc:footprintWKT',\n",
       " 'dwc:formation',\n",
       " 'dwc:genus',\n",
       " 'dwc:geodeticDatum',\n",
       " 'dwc:geologicalContextID',\n",
       " 'dwc:georeferenceProtocol',\n",
       " 'dwc:georeferenceRemarks',\n",
       " 'dwc:georeferenceSources',\n",
       " 'dwc:georeferenceVerificationStatus',\n",
       " 'dwc:georeferencedBy',\n",
       " 'dwc:georeferencedDate',\n",
       " 'dwc:group',\n",
       " 'dwc:habitat',\n",
       " 'dwc:higherClassification',\n",
       " 'dwc:higherGeography',\n",
       " 'dwc:higherGeographyID',\n",
       " 'dwc:highestBiostratigraphicZone',\n",
       " 'dwc:identificationID',\n",
       " 'dwc:identificationQualifier',\n",
       " 'dwc:identificationReferences',\n",
       " 'dwc:identificationRemarks',\n",
       " 'dwc:identificationVerificationStatus',\n",
       " 'dwc:identifiedBy',\n",
       " 'dwc:individualCount',\n",
       " 'dwc:informationWithheld',\n",
       " 'dwc:infraspecificEpithet',\n",
       " 'dwc:institutionCode',\n",
       " 'dwc:institutionID',\n",
       " 'dwc:island',\n",
       " 'dwc:islandGroup',\n",
       " 'dwc:kingdom',\n",
       " 'dwc:language',\n",
       " 'dwc:latestAgeOrHighestStage',\n",
       " 'dwc:latestEonOrHighestEonothem',\n",
       " 'dwc:latestEpochOrHighestSeries',\n",
       " 'dwc:latestEraOrHighestErathem',\n",
       " 'dwc:latestPeriodOrHighestSystem',\n",
       " 'dwc:lifeStage',\n",
       " 'dwc:lithostratigraphicTerms',\n",
       " 'dwc:locality',\n",
       " 'dwc:locationAccordingTo',\n",
       " 'dwc:locationID',\n",
       " 'dwc:locationRemarks',\n",
       " 'dwc:lowestBiostratigraphicZone',\n",
       " 'dwc:materialSampleID',\n",
       " 'dwc:maximumDepthInMeters',\n",
       " 'dwc:maximumElevationInMeters',\n",
       " 'dwc:member',\n",
       " 'dwc:minimumDepthInMeters',\n",
       " 'dwc:minimumElevationInMeters',\n",
       " 'dwc:modified',\n",
       " 'dwc:month',\n",
       " 'dwc:municipality',\n",
       " 'dwc:nameAccordingTo',\n",
       " 'dwc:namePublishedIn',\n",
       " 'dwc:namePublishedInID',\n",
       " 'dwc:namePublishedInYear',\n",
       " 'dwc:nomenclaturalCode',\n",
       " 'dwc:nomenclaturalStatus',\n",
       " 'dwc:occurrenceDetails',\n",
       " 'dwc:occurrenceID',\n",
       " 'dwc:occurrenceRemarks',\n",
       " 'dwc:occurrenceStatus',\n",
       " 'dwc:order',\n",
       " 'dwc:organismID',\n",
       " 'dwc:organismName',\n",
       " 'dwc:organismQuantity',\n",
       " 'dwc:organismQuantityType',\n",
       " 'dwc:organismRemarks',\n",
       " 'dwc:originalNameUsage',\n",
       " 'dwc:otherCatalogNumbers',\n",
       " 'dwc:ownerInstitutionCode',\n",
       " 'dwc:parentNameUsage',\n",
       " 'dwc:phylum',\n",
       " 'dwc:pointRadiusSpatialFit',\n",
       " 'dwc:preparations',\n",
       " 'dwc:previousIdentifications',\n",
       " 'dwc:recordNumber',\n",
       " 'dwc:recordedBy',\n",
       " 'dwc:reproductiveCondition',\n",
       " 'dwc:rights',\n",
       " 'dwc:rightsHolder',\n",
       " 'dwc:sampleSizeValue',\n",
       " 'dwc:samplingEffort',\n",
       " 'dwc:samplingProtocol',\n",
       " 'dwc:scientificName',\n",
       " 'dwc:scientificNameAuthorship',\n",
       " 'dwc:scientificNameID',\n",
       " 'dwc:sex',\n",
       " 'dwc:specificEpithet',\n",
       " 'dwc:startDayOfYear',\n",
       " 'dwc:stateProvince',\n",
       " 'dwc:subgenus',\n",
       " 'dwc:taxonID',\n",
       " 'dwc:taxonRank',\n",
       " 'dwc:taxonRemarks',\n",
       " 'dwc:taxonomicStatus',\n",
       " 'dwc:typeStatus',\n",
       " 'dwc:verbatimCoordinateSystem',\n",
       " 'dwc:verbatimCoordinates',\n",
       " 'dwc:verbatimDepth',\n",
       " 'dwc:verbatimElevation',\n",
       " 'dwc:verbatimEventDate',\n",
       " 'dwc:verbatimLatitude',\n",
       " 'dwc:verbatimLocality',\n",
       " 'dwc:verbatimLongitude',\n",
       " 'dwc:verbatimSRS',\n",
       " 'dwc:verbatimTaxonRank',\n",
       " 'dwc:vernacularName',\n",
       " 'dwc:waterBody',\n",
       " 'dwc:year',\n",
       " 'gbif:Identifier',\n",
       " 'gbif:Reference',\n",
       " 'gbif:identifiedByID',\n",
       " 'gbif:recordedByID',\n",
       " 'idigbio:recordId',\n",
       " 'symbiota:recordEnteredBy',\n",
       " 'symbiota:verbatimScientificName',\n",
       " 'zan:ChronometricDate']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_headers('occurrence_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T17:06:25.102742Z",
     "start_time": "2021-03-03T17:06:25.100987Z"
    }
   },
   "outputs": [],
   "source": [
    "# load_data('occurrence_raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duck DB doubles the size of the data so we are not using it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic plan is:\n",
    "\n",
    "1. Extract occurrence_raw.csv from an iDigBio snapshot\n",
    "1. Get the headers and rename the columns so they'll work in a DB\n",
    "1. Split the CSV file into sizes that will fit in memory\n",
    "1. Load the CSV splits into the database\n",
    "1. Clean up the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make working with the database a bit easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the needed CSV file from the zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip -p $ZIP occurrence_raw.csv > $CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the CSV file into manageable chunks that fit in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !split --additional-suffix=.csv --numeric-suffixes=1 --lines=$LINES $CSV $PREFIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the first file with the header so it can be removed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mv $FIRST $BACKUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the headers from the first file. We need to rename the column headers in the DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(BACKUP) as in_file:\n",
    "#     headers = in_file.readline()\n",
    "# headers = [h.strip() for h in headers.split(',')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the old header from that first file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tail -n +2 $BACKUP > $FIRST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the backup file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm $BACKUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad_names = \"\"\" group order references \"\"\".split()\n",
    "\n",
    "# def get_columns(headers):\n",
    "#     columns = {}\n",
    "#     used = set()\n",
    "\n",
    "#     for head in headers:\n",
    "#         col = head.split(':')[-1]\n",
    "#         col = re.sub(r'(?<![A-Z])([A-Z])', r'_\\1', col).lower()\n",
    "#         col = re.sub(r'^_', '', col)\n",
    "#         if col in used:\n",
    "#             col = head.replace(':', '_')\n",
    "#             col = re.sub(r'(?<![A-Z])([A-Z])', r'_\\1', col).lower()\n",
    "#             col = re.sub(r'^_', '', col)\n",
    "#         if col in bad_names:\n",
    "#             col += '_'\n",
    "#         columns[head] = col\n",
    "#         used.add(col)\n",
    "#     return columns\n",
    "\n",
    "\n",
    "# columns = get_columns(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a table with the new column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = [f'{h} VARCHAR' for h in columns.values()]\n",
    "# columns = ', '.join(columns)\n",
    "\n",
    "# with duckdb_connect(DB) as cxn:\n",
    "#     cxn.execute(f'CREATE TABLE raw_data ({columns});')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy CSV data into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths = sorted(DATA_DIR.glob(GLOB))\n",
    "\n",
    "# for path in tqdm(paths):\n",
    "#     with duckdb_connect(DB) as cxn:\n",
    "#         cxn.execute(f\"COPY raw_data FROM '{str(path)}';\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unneeded files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path in paths:\n",
    "#     path.unlink()\n",
    "\n",
    "# Path(CSV).unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T12:52:32.402771Z",
     "start_time": "2020-05-09T12:41:37.652865Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0+"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
