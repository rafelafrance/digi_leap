{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T14:36:11.918372Z",
     "start_time": "2020-05-11T14:36:11.690332Z"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import sqlite3\n",
    "import zipfile\n",
    "from contextlib import contextmanager\n",
    "from pathlib import Path\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T14:36:11.921771Z",
     "start_time": "2020-05-11T14:36:11.919492Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = Path('..') / 'data'\n",
    "\n",
    "NAME = 'occurrence_raw_idigbio_2021-02'\n",
    "\n",
    "ZIP = str(DATA_DIR / 'iDigBio_snapshot_2021-02.zip')\n",
    "DB = str(DATA_DIR / f'{NAME}.duckdb.db')\n",
    "CSV = str(DATA_DIR / f'{NAME}.csv')\n",
    "\n",
    "PREFIX = str(DATA_DIR / f'{NAME}_')\n",
    "FIRST = f'{PREFIX}01.csv'\n",
    "BACKUP = f'{PREFIX}01_header.csv'\n",
    "GLOB = PREFIX + '*.csv'\n",
    "\n",
    "CHUNK = 1_000_000\n",
    "LINES = 5_000_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make working with the database a bit easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def duckdb_connect(db=':memory:'):\n",
    "    db = str(db)\n",
    "    cxn = duckdb.connect(db)\n",
    "    try:\n",
    "        yield cxn\n",
    "    finally:\n",
    "        cxn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the needed CSV file from the zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip -p $ZIP occurrence_raw.csv > $CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the CSV file into manageable chunks that fit in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!split --additional-suffix=.csv --numeric-suffixes=1 --lines=$LINES $CSV $PREFIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the first file with the header so it can be removed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv $FIRST $BACKUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the headers from the first file. We need to rename the column headers in the DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(BACKUP) as in_file:\n",
    "    headers = in_file.readline()\n",
    "headers = [h.strip() for h in headers.split(',')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the old header from that first file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tail -n +2 $BACKUP > $FIRST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the backup file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm $BACKUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_names = \"\"\" group order references \"\"\".split()\n",
    "\n",
    "def get_columns(headers):\n",
    "    columns = {}\n",
    "    used = set()\n",
    "\n",
    "    for head in headers:\n",
    "        col = head.split(':')[-1]\n",
    "        col = re.sub(r'(?<![A-Z])([A-Z])', r'_\\1', col).lower()\n",
    "        col = re.sub(r'^_', '', col)\n",
    "        if col in used:\n",
    "            col = head.replace(':', '_')\n",
    "            col = re.sub(r'(?<![A-Z])([A-Z])', r'_\\1', col).lower()\n",
    "            col = re.sub(r'^_', '', col)\n",
    "        if col in bad_names:\n",
    "            col += '_'\n",
    "        columns[head] = col\n",
    "        used.add(col)\n",
    "    return columns\n",
    "\n",
    "\n",
    "columns = get_columns(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a table with the new column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [f'{h} VARCHAR' for h in columns.values()]\n",
    "columns = ', '.join(columns)\n",
    "\n",
    "with duckdb_connect(DB) as cxn:\n",
    "    cxn.execute(f'CREATE TABLE raw_data ({columns});')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy CSV data into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [40:35<00:00, 93.67s/it] \n"
     ]
    }
   ],
   "source": [
    "paths = sorted(DATA_DIR.glob(GLOB))\n",
    "\n",
    "for path in tqdm(paths):\n",
    "    with duckdb_connect(DB) as cxn:\n",
    "        cxn.execute(f\"COPY raw_data FROM '{str(path)}';\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unneeded files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    path.unlink()\n",
    "\n",
    "Path(CSV).unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This uses sqlite3 which is not appropriate for our needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_headers(zip_file):\n",
    "#     with zipfile.ZipFile(ZIP) as zippy:\n",
    "#         with zippy.open(zip_file) as in_file:\n",
    "#             headers = in_file.readline()\n",
    "#     return [h.decode().strip() for h in sorted(headers.split(b','))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_columns(headers):\n",
    "#     columns = {}\n",
    "#     used = set()\n",
    "\n",
    "#     for head in headers:\n",
    "#         col = head.split(':')[-1]\n",
    "#         col = re.sub(r'(?<![A-Z])([A-Z])', r'_\\1', col).lower()\n",
    "#         col = re.sub(r'^_', '', col)\n",
    "#         if col in used:\n",
    "#             col = head.replace(':', '_')\n",
    "#             col = re.sub(r'(?<![A-Z])([A-Z])', r'_\\1', col).lower()\n",
    "#             col = re.sub(r'^_', '', col)\n",
    "#         columns[head] = col\n",
    "#         used.add(col)\n",
    "#     return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T14:36:13.279309Z",
     "start_time": "2020-05-11T14:36:13.274430Z"
    }
   },
   "outputs": [],
   "source": [
    "# def insert(zip_file, columns):\n",
    "#     table = zip_file.split('.')[0]\n",
    "\n",
    "#     with sqlite3.connect(DB) as cxn:\n",
    "#         with zipfile.ZipFile(ZIP) as zippy:\n",
    "#             with zippy.open(zip_file) as in_file:\n",
    "\n",
    "#                 reader = pd.read_csv(\n",
    "#                     in_file, dtype=str, keep_default_na=False, chunksize=CHUNK)\n",
    "\n",
    "#                 if_exists = 'replace'\n",
    "\n",
    "#                 for df in tqdm(reader):\n",
    "#                     df = df.rename(columns=columns)\n",
    "\n",
    "#                     df.to_sql(table, cxn, if_exists=if_exists, index=False)\n",
    "\n",
    "#                     if_exists = 'append'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T14:36:13.287941Z",
     "start_time": "2020-05-11T14:36:13.280354Z"
    }
   },
   "outputs": [],
   "source": [
    "# def wrapper(zip_file):\n",
    "#     headers = get_headers(zip_file)\n",
    "#     columns = get_columns(headers)\n",
    "#     insert(zip_file, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T15:46:27.792919Z",
     "start_time": "2020-05-11T15:03:49.943773Z"
    }
   },
   "outputs": [],
   "source": [
    "# wrapper('occurrence_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T12:52:32.402771Z",
     "start_time": "2020-05-09T12:41:37.652865Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0+"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
