{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f1d91f3-a0c5-4ee2-926e-2091aa6a374e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Measure contributions of parts of OCR pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a5b980-67c5-41e7-b49e-1bab3d17d789",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Possible OCR pipelines (actions are green)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03270b28-13a7-4cd9-8f66-a7d8ebc0853a",
   "metadata": {},
   "source": [
    "![ocr_flow](assets/ocr_flow.drawio.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154a51cd-2831-40b0-b316-81c9926168c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### The are 4 groups of actions in the full pipeline (green boxes). The purpose of this notebook is to test if all of these actions really helps with the OCR results, and if they do, by how much.\n",
    "\n",
    "- **Find the single best ensemble.**\n",
    "- Which of the 4 image processing pipelines improve OCR performance?\n",
    "- Two OCR engines: `Tesseract` & `EasyOCR`. `Tesseract` is the current leader in open source OCR engines, does adding `EasyOCR` improve the results?\n",
    "- The `combine text` function is only needed if we stick with the ensemble approach. I.e. only if we use more than one image processing pipeline or more than one OCR engine.\n",
    "- The `clean text` function corrects misspellings and common OCR errors with punctuation, spacing, etc. We want to measure its efficacy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cf0268-53f0-4272-b002-e4d67a04c898",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Comparison strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138c7d10-a9f7-403e-80b7-39cd294129e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### We're doing ablations on the OCR pipeline.\n",
    "- How well do `Tesseract` and `EasyOCR` perform on their own without image pre-processing. I'll also try the engine directly grafted to the `clean text` function.\n",
    "- How well do each of the image pre-processing steps help the OCR process? and which ones work well with which OCR engine. I'm going to try various permutations of these.\n",
    "- Can I whittle this down to one or zero image pre-processing pipelines and one OCR engine? If so, then this would allow me to drop the `combine text` step.\n",
    "- How much does the `clean text` step help?\n",
    "- Note that `EasyOCR` uses a fair bit of GPU resources and if we can remove it it will speed up the OCR pipeline significantly. I.e. `EasyOCR` is difficult to parallelize.\n",
    "\n",
    "#### Scoring\n",
    "- I'll use an expert derived gold standard to compare against the ablation sequences.\n",
    "- I am using Levenshtein distance as the scores. Levenshtein distance counts character mismatches between sequences in a best case pairwise alignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2158239-7ae2-4812-b2ed-9e5cc63083e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e14a709-4d3f-475d-aac3-05f11b996f1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from IPython.display import display, HTML\n",
    "from collections import defaultdict, namedtuple\n",
    "from colorama import Back, Fore, Style\n",
    "from itertools import groupby\n",
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "\n",
    "from digi_leap.pylib import consts\n",
    "from digi_leap.pylib.ocr import ocr_compare as compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71b0edf4-cd7f-42a1-a901-310fb7b0f294",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73ec813d-d7e5-4ab0-8dd4-6b839268727d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARGS = SimpleNamespace(\n",
    "    database=Path(consts.DATA_DIR / \"sernec\" / \"sernec.sqlite\"),\n",
    "    gold_set=\"test_gold_set\",\n",
    "    score_set=\"notebook_scores\",\n",
    "    notes=\"\",\n",
    "    csv_path=consts.DATA_DIR / \"sernec\" / \"gold_std_2022-06-28_sample.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05affe5-8c3f-4efe-bbdc-ba2faac6098e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Gold standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ce5caba-a91e-4b62-a2c3-bf15410f2f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a new gold standard to a database\n",
    "\n",
    "# comp.insert_gold_std(ARGS.csv_path, ARGS.database, ARGS.gold_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c9f7fc4-afe7-45d5-977a-d6dc2df81727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a gold standard for the database\n",
    "\n",
    "GOLD_STD = compare.select_gold_std(ARGS.database, ARGS.gold_set)\n",
    "GOLD_DICT = {g[\"gold_id\"]: g for g in GOLD_STD}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f418c1-45ad-4a68-9b7d-60e80a8945b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## OCR scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89bbc4f9-707a-42ef-8288-ec84d8116e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = compare.Scorer(ARGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f41ae18-427f-4fc9-9008-55bf19a5bac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [01:36<00:00, 24.05s/it]\n"
     ]
    }
   ],
   "source": [
    "# Calculate new scores\n",
    "\n",
    "# SCORES = scorer.calculate(GOLD_STD)\n",
    "# scorer.insert_scores(SCORES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea11a33a-a4d3-496f-8d34-0b0d931a9704",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORES = scorer.select_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcd77b7-b28e-42a6-9ac7-7f7960ec4852",
   "metadata": {},
   "source": [
    "## Examine scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7c7959e-6b22-4ad5-a7e2-a1df677ecd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peek_scores(scores):\n",
    "    grouped_scores = groupby(scores, key=lambda s: s[\"label_id\"])\n",
    "\n",
    "    for labels_id, scores in grouped_scores:\n",
    "        print(\"=\" * 80)\n",
    "        print(labels_id)\n",
    "        scores = sorted(\n",
    "            scores, key=lambda s: (s[\"score\"], len(json.loads(s[\"actions\"])))\n",
    "        )\n",
    "        for score in scores:\n",
    "            print(f\"{score['score']:4d}  {score['actions']}\")\n",
    "\n",
    "\n",
    "# peek_scores(SCORES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd408d7d-af0c-43ec-8c3f-07d0eb627b83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71341  7\n",
      "FLORA OF ALABAMA Pike County No. 15 Botanical Name Iris virginica L. Family Iridaceae Locality Pocosin 6 mi. E. Troy Ala. Col. by J\u001b[102m\u001b[37m⋄\u001b[0m. Popham Det. by \u001b[102m\u001b[37mJ\u001b[0m\u001b[102m\u001b[37m.\u001b[0m\u001b[102m\u001b[37m \u001b[0m\u001b[102m\u001b[37mP\u001b[0mopha\u001b[102m\u001b[37mm\u001b[0m Date 3\u001b[102m\u001b[37m-\u001b[0m29-67 Remarks: Herbarium of Troy State College\n",
      "FLORA OF ALABAMA Pike County No. 15 Botanical Name Iris virginica L. Family Iridaceae Locality Pocosin 6 mi. E. Troy Ala. Col. by J\u001b[102m\u001b[37m+\u001b[0m. Popham Det. by \u001b[102m\u001b[37mL\u001b[0m\u001b[102m\u001b[37m⋄\u001b[0m\u001b[102m\u001b[37m⋄\u001b[0m\u001b[102m\u001b[37m⋄\u001b[0mopha\u001b[102m\u001b[37m⋄\u001b[0m Date 3\u001b[102m\u001b[37m=\u001b[0m29-67 Remarks: Herbarium of Troy State College\n",
      "\n",
      "71540  4\n",
      "HERBARIUM OF NORTHEAST LOUISIANA UNIVERSITY, MONROE FLORA OF LOUISIANA Parish: RAP\u001b[102m\u001b[37mI\u001b[0mDES Solidago altissima L. Along Lake Buhlow Airport Road and lake, off \u001b[102m\u001b[37mo\u001b[0mf US 165\u001b[102m\u001b[37m.\u001b[0m Outside of Alexandria, La. Sec. 16, T2N, R\u001b[102m\u001b[37m1\u001b[0mE. Collector: Steven Schutz, Christy Schutz No.: 1095 Date: 4 Sept. 1977\n",
      "HERBARIUM OF NORTHEAST LOUISIANA UNIVERSITY, MONROE FLORA OF LOUISIANA Parish: RAP\u001b[102m\u001b[37mL\u001b[0mDES Solidago altissima L. Along Lake Buhlow Airport Road and lake, off \u001b[102m\u001b[37m0\u001b[0mf US 165\u001b[102m\u001b[37m,\u001b[0m Outside of Alexandria, La. Sec. 16, T2N, R\u001b[102m\u001b[37mL\u001b[0mE. Collector: Steven Schutz, Christy Schutz No.: 1095 Date: 4 Sept. 1977\n",
      "\n",
      "71640  2\n",
      "HERBARIUM NORTHEAST LOUISIANA UNIVERSITY, MONROE Flora of LOUISIANA Parish: AVOYELLES RHUS GLABRA L. Woods and gas line right-of-way west of I-49 and south of La. 115 southeast of U.S. 167; Sec. 32,\u001b[102m\u001b[37mT\u001b[0m\u001b[102m\u001b[37m1\u001b[0mS, R2E. Clay soil. Collector: R. Dale Thomas No.: 118,918 Date: 14 June 1990\n",
      "HERBARIUM NORTHEAST LOUISIANA UNIVERSITY, MONROE Flora of LOUISIANA Parish: AVOYELLES RHUS GLABRA L. Woods and gas line right-of-way west of I-49 and south of La. 115 southeast of U.S. 167; Sec. 32,\u001b[102m\u001b[37m \u001b[0m\u001b[102m\u001b[37mW\u001b[0mS, R2E. Clay soil. Collector: R. Dale Thomas No.: 118,918 Date: 14 June 1990\n",
      "HERBARIUM NORTHEAST LOUISIANA UNIVERSITY, MONROE Flora of LOUISIANA Parish: AVOYELLES RHUS GLABRA L. Woods and gas line right-of-way west of I-49 and south of La. 115 southeast of U.S. 167; Sec. 32,\u001b[102m\u001b[37m \u001b[0m\u001b[102m\u001b[37mW\u001b[0mS, R2E. Clay soil. Collector: R. Dale Thomas No.: 118,918 Date: 14 June 1990\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "One of 'h¼' these characters are missing from the substitution matrix.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(ln))\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m---> 35\u001b[0m \u001b[43mmsa_top_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSCORES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGOLD_DICT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mline_align\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36mmsa_top_scores\u001b[0;34m(scores, gold_std, line_align)\u001b[0m\n\u001b[1;32m      9\u001b[0m top \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [s[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore_text\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m scores \u001b[38;5;28;01mif\u001b[39;00m s[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m min_score]\n\u001b[1;32m     10\u001b[0m top \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(ln\u001b[38;5;241m.\u001b[39msplit()) \u001b[38;5;28;01mfor\u001b[39;00m ln \u001b[38;5;129;01min\u001b[39;00m top]\n\u001b[0;32m---> 11\u001b[0m aligned \u001b[38;5;241m=\u001b[39m \u001b[43mline_align\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmin_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(aligned)\n",
      "\u001b[0;31mValueError\u001b[0m: One of 'h¼' these characters are missing from the substitution matrix."
     ]
    }
   ],
   "source": [
    "def msa_top_scores(scores, gold_std, line_align):\n",
    "    grouped_scores = groupby(scores, key=lambda s: s[\"label_id\"])\n",
    "\n",
    "    for label_id, scores in grouped_scores:\n",
    "        scores = list(scores)\n",
    "        gold = gold_std[scores[0][\"gold_id\"]]\n",
    "        min_score = min(s[\"score\"] for s in scores)\n",
    "        top = [gold[\"gold_text\"]]\n",
    "        top += [s[\"score_text\"] for s in scores if s[\"score\"] == min_score]\n",
    "        top = [\" \".join(ln.split()) for ln in top]\n",
    "        aligned = line_align.align(top)\n",
    "\n",
    "        print(f\"{label_id}  {min_score}\")\n",
    "\n",
    "        rows = len(aligned)\n",
    "        cols = len(aligned[0])\n",
    "        colored = [list(a) for a in aligned]\n",
    "\n",
    "        for col in range(cols):\n",
    "            col_chars = [aligned[row][col] for row in range(rows)]\n",
    "            if len(set(col_chars)) > 1:\n",
    "                for row in range(rows):\n",
    "                    colored[row][col] = (\n",
    "                        Back.LIGHTGREEN_EX\n",
    "                        + Fore.WHITE\n",
    "                        + colored[row][col]\n",
    "                        + Style.RESET_ALL\n",
    "                    )\n",
    "\n",
    "        for ln in colored:\n",
    "            print(\"\".join(ln))\n",
    "        print()\n",
    "\n",
    "\n",
    "msa_top_scores(SCORES, GOLD_DICT, scorer.line_align)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e15f03-0307-4705-84c3-ee3904a114bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "PipelineScore = namedtuple(\"PipelineScore\", \"score pipeline\")\n",
    "\n",
    "\n",
    "def scores_by_pipeline(scores, gold_std):\n",
    "    tally = defaultdict(int)\n",
    "\n",
    "    for score in scores:\n",
    "        tally[score[\"actions\"]] += score[\"score\"]\n",
    "\n",
    "    tally = [(v, len(a), a) for k, v in tally.items() if (a := json.loads(k))]\n",
    "    tally = sorted(tally)\n",
    "    return [PipelineScore(t[0], t[2]) for t in tally]\n",
    "\n",
    "\n",
    "summed = scores_by_pipeline(SCORES, GOLD_DICT)\n",
    "\n",
    "for sum_ in summed:\n",
    "    print(sum_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49523ee4-dc14-458a-a657-e5df523d9630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f300940-62ce-4594-9bd7-dd76281a597c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
